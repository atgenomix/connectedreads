# Job Configuration
#   An Aztk Job is a cluster and an array of Spark applications to run on that cluster
#   AZTK Spark Jobs will automatically manage the lifecycle of the cluster
#   For more information see the documentation at: http://aztk.readthedocs.io/en/latest/70-jobs.html

job:
    cluster_configuration:
        worker_on_master: true
        vm_size: Standard_D13_v2
        size: 0
        size_low_priority: 10
        toolkit:
          software: spark
          version: 2.3.0
          docker_repo: atgenomix/seqslab_runtime_1.0
          # docker_run_options: --shm-size="10g" --device /dev/fuse --privileged --env TEST="test"

    spark_configuration:
        spark_defaults_conf: spark-defaults.assembly.conf
        spark_env_sh: spark-env.sh
        core_site_xml: core-site.xml

    # an application maps directly to a spark-submit command
    applications:
      - name: assemble
        application: /${JAR_FOLDER}/connectedreads-1.0.0.jar
        application_args:
          - overlap
          - ${INPUT_VT_FOLDER}
          - ${INPUT_ED_FOLDER}
          - ${OUTPUT_FOLDER}
          - ${TMP_FOLDER}
          - -input_format
          - PARQUET
          - -mod
          - 3
          - -small_steps
          - 5
          - -big_steps
          - 400
          - -denoise_len
          - 151
          - -intersection
          - 1
          - -ploidy
          - 2
          - -partition
          - 2100
          - -one_to_one_profiling
          - -ee
          - 40
          - -fpp
          - 0.001
          - -degree_profiling
       main_class: com.atgenomix.connectedreads.cli.GraphSeqMain
